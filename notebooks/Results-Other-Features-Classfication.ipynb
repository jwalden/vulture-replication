{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification with other features\n",
    "* Zweck: Validierung von Klassifikation mit anderen Features als Includes und Function Calls.\n",
    "* Matrix: Aktueller Stand \"current\" des mozilla-central Repository\n",
    "* Features: Includes, Function Calls, Definitions, Names, Conditions\n",
    "* Modell: Support Vector Machine Classifier\n",
    "\n",
    "#### Setup\n",
    "* Training-Set/Test-Set: Stratified sampling auf einer Matrix (2/3 : 1/3)\n",
    "\n",
    "#### Results\n",
    "Tabellarischer Vergleich der durchschnittlichen Precision und Recall Werte für verschiedene Features bei n=5 Experimenten. Weiter werden die Anzahl extrahierter Features und die durchschnittliche Laufzeit für das Trainieren des Modells aufgelistet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Includes (current) - done 1/10\n",
      " * Includes (history) - done 2/10\n",
      " * Conditions (current) - done 3/10\n",
      " * Conditions (history) - done 4/10\n",
      " * Definitions (current) - done 5/10\n",
      " * Definitions (history) - done 6/10\n",
      " * Names (current) - done 7/10\n",
      " * Names (history) - done 8/10\n",
      " * Function Calls (current) - done 9/10\n",
      " * Function Calls (history) - done 10/10\n",
      "+--------------------------+---------------+-----------+--------+------------------+\n",
      "|         Features         | Feature count | Precision | Recall | Time for fitting |\n",
      "+--------------------------+---------------+-----------+--------+------------------+\n",
      "|    Includes (current)    |     15362     |   0.556   | 0.391  |     0.05min      |\n",
      "|    Includes (history)    |     16383     |   0.669   | 0.573  |     0.06min      |\n",
      "|   Conditions (current)   |     19417     |   0.657   | 0.159  |     0.06min      |\n",
      "|   Conditions (history)   |     19926     |   0.750   | 0.332  |     0.06min      |\n",
      "|  Definitions (current)   |     77527     |   0.640   | 0.083  |     0.44min      |\n",
      "|  Definitions (history)   |     79832     |   0.657   | 0.237  |     0.51min      |\n",
      "|     Names (current)      |      744      |   0.565   | 0.094  |     0.00min      |\n",
      "|     Names (history)      |      772      |   0.652   | 0.142  |     0.00min      |\n",
      "| Function Calls (current) |     220191    |   0.649   | 0.386  |     11.19min     |\n",
      "| Function Calls (history) |     237280    |   0.722   | 0.653  |     8.35min      |\n",
      "+--------------------------+---------------+-----------+--------+------------------+\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from prettytable import PrettyTable\n",
    "\n",
    "from imports.matrix_helper import MatrixHelper\n",
    "from imports.prediction_helper import PredictionHelper\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "matrix_helper = MatrixHelper()\n",
    "experiments_per_feature = 5\n",
    "counter = 1\n",
    "\n",
    "features = [('incl', 'Includes'), ('cond', 'Conditions'), ('defs', 'Definitions'), ('names', 'Names'), ('calls', 'Function Calls')]\n",
    "table = PrettyTable(['Features', 'Feature count', 'Precision', 'Recall', 'Time for fitting'])\n",
    "\n",
    "for feature in features:\n",
    "    for h_type in ['current', 'history']:\n",
    "        # Read pickle\n",
    "        matrices = matrix_helper.load_from_parse('data/matrices/matrix_cla_' + feature[0] + '_' + h_type + '.pickle')\n",
    "        \n",
    "        precision_list = []\n",
    "        recall_list = []\n",
    "        time_list = []\n",
    "        \n",
    "        for i in range(experiments_per_feature):\n",
    "            # Instantiate Prediction Helper Class and predict values for compare matrix with an SVM\n",
    "            prediction_helper = PredictionHelper()\n",
    "            prediction_helper.calculate_validation_compare_matrix(matrices, sampling_factor=(2.0/3), prediction_type='LinearSVC', crop_matrix=False)\n",
    "            compare_matrix = prediction_helper.get_compare_matrix()\n",
    "\n",
    "            # Compute Precision-Recall\n",
    "            precision, recall, thresholds = precision_recall_curve(np.array(compare_matrix[:, 2], dtype='f'), np.array(compare_matrix[:, 1], dtype='f'))\n",
    "            precision_list.append(precision[1])\n",
    "            recall_list.append(recall[1])\n",
    "            time_list.append(prediction_helper.time)\n",
    "\n",
    "        divisor = float(experiments_per_feature)\n",
    "        feature_name = \"{} ({})\".format(feature[1], h_type)\n",
    "        precision = \"{:.3f}\".format(sum(precision_list)/divisor)\n",
    "        recall = \"{:.3f}\".format(sum(recall_list)/divisor)\n",
    "        time = \"{:.2f}min\".format(sum(time_list)/divisor)\n",
    "        \n",
    "        table.add_row([feature_name, len(matrices[2]), precision, recall, time])\n",
    "        print(' * {} - done {}/{}'.format(feature_name, counter, 2 * len(features)))\n",
    "        counter += 1\n",
    "\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
