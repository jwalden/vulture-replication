{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Test: Bestimmung Precision / Recall mit SVM\n",
    "Um die Klassifikation, und damit auch von dem Aufbau unserer Matrix, zu testen, bestimmen wir Precision und Recall mit einer SVM.\n",
    "\n",
    "* Precision: Wieviele der zugeordneten Samples sind tatsächlich relevant? (true pos.) / (true pos. + false pos.)\n",
    "* Recall: Wieviele der tatsächlich relevanten Samples wurden gefunden / zugeordnet? (true pos.) / (true pos. + false neg.)\n",
    " * Tiefe Precision / hoher Recall: Es werden viele Samples zugeordnet, von denen jedoch viele falsch sind\n",
    " * Hohe Precision / tiefer Recall: Es werden nur wenige Samples zugeordnet, von denen jedoch die meisten stimmen.\n",
    "<img src=\"img/Precisionrecall.png\" alt=\"Drawing\" style=\"width: 200px\"/>\n",
    "\n",
    "## Optimierung\n",
    "Mit diesem Test versuchen wir die Konfiguration der SVM möglichst gut auf unsere Datenstruktur auszurichten.\n",
    "### Kernel\n",
    "Der Kernel definiert, mit welcher Art Funktion die Datenpunkte im 2D-Raum voneinander getrennt werden. Standardmässig wird dazu eine lineare Funktion (linear kernel) verwendet. Wenn die Punkte im training set nicht durch eine Gerade trennbar sind, versucht man sie in einer höheren Dimension voneinander zu trennen. Die erreicht man durch andere kernel-Funktionen (z.B. Polynomial oder RBF).\n",
    "Bei vielen Features, wie es bei unseren Daten der Fall ist, bringt eine höhere Dimension keine Vorteile, ist aber sehr teuer. Entsprechend verwenden wir einen linearen Kernel.\n",
    "\n",
    "#### Parameter\n",
    "Der lineare Kernel verlangt ausschliesslich einen Penalty Parameter C. Beim einem hohen C versucht der Classifier die Ebene so zu legen, dass möglichst wenige Datenpunkte aus dem training set falsch klassifiziert sind. Dafür nimmt er ein kleineres Margin zwischen Ebene und Punkte in Kauf. Bei einem tiefen Wert für C sucht der Classifier nach einem möglichst hohen margin, nimmt aber falsche Klassifizierungen im trianing set in Kauf.\n",
    "\n",
    "### Bestimmung Parameter C\n",
    "Evaluation mit 2000 samples im test set:\n",
    "* C=0.1: Precision 0.777777777778, Recall 0.21875\n",
    "* C=0.2: Precision 0.785714285714, Recall 0.34375\n",
    "* C=0.3: Precision 0.769230769231, Recall 0.3125\n",
    "* C=0.4: Precision 0.714285714286, Recall 0.3125\n",
    "* C=0.5: Precision 0.666666666667, Recall 0.3125\n",
    "* C=0.6: Precision 0.555555555556, Recall 0.3125\n",
    "* C=0.7: Precision 0.555555555556, Recall 0.3125\n",
    "* C=0.8: Precision 0.578947368421, Recall 0.34375\n",
    "* C=0.9: Precision 0.578947368421, Recall 0.34375\n",
    "* C=1: Precision 0.578947368421, Recall 0.34375\n",
    "\n",
    "### Test mit Parameter C\n",
    "#### Test mit Matrix V1\n",
    "C=0.2\n",
    "* Samples 1000: Precision 1.0, Recall 0.240740740741\n",
    "* Samples 2000: Precision 0.833333333333, Recall 0.37037037037\n",
    "* Samples 5000: Precision 0.785714285714, Recall 0.407407407407\n",
    "* Samples 10000: Precision 0.821428571429, Recall 0.425925925926\n",
    "* Samples 15000: Precision 0.896551724138, Recall 0.481481481481\n",
    "\n",
    "#### Test mit Matrix V2 \n",
    "C=0.2\n",
    "* Samples 1000: Precision 1.0, Recall 0.327272727273\n",
    "* Samples 2000: Precision 0.9375, Recall 0.545454545455\n",
    "* Samples 5000: Precision 0.885714285714, Recall 0.563636363636\n",
    "* Samples 10000: Precision 0.861111111111, Recall 0.563636363636\n",
    "* Samples 15000: Precision 0.916666666667, Recall 0.6\n",
    "\n",
    "Samples=15000\n",
    "* C=0.2: Precision 0.916666666667, Recall 0.6\n",
    "* C=0.6: Precision 0.888888888889, Recall 0.727272727273\n",
    "* C=1.0: Precision 0.816326530612, Recall 0.727272727273\n",
    "\n",
    "#### Test mit 1/3 und 2/3 bei 15000 Samples\n",
    "* #1: Precision 0.955922865014, Recall 0.805104408353\n",
    "* #2: Precision 0.937555753791, Recall 0.812838360402\n",
    "* #3: Precision 0.956014362657, Recall 0.823665893271\n",
    "* #4: Precision 0.950628366248, Recall 0.819025522042\n",
    "* #5: Precision 0.946654611212, Recall 0.809744779582\n",
    "\n",
    "#### Test mit Matrix V3\n",
    "* #1: Precision 0.89219858156, Recall 0.643807574207\n",
    "\n",
    "#### Test mit Klassifikationsmatrix\n",
    "* #1: Precision 0.89248434238, Recall 0.707196029777\n",
    "* #2: Precision 0.887804878049, Recall 0.752688172043\n",
    "* #3: Precision 0.897177419355, Recall 0.736145574855\n",
    "* #4: Precision 0.881592039801, Recall 0.732837055418\n",
    "* #5: Precision 0.893551688843, Recall 0.722084367246\n",
    "* #6: Precision 0.892966360856, Recall 0.724565756824\n",
    "* #7: Precision 0.89296333003, Recall 0.745244003309\n",
    "* #8: Precision 0.895895895896, Recall 0.740281224152\n",
    "* #9: Precision 0.886294416244, Recall 0.722084367246\n",
    "* #10: Precision 0.896586345382, Recall 0.738626964433\n",
    "* #11: Precision 0.8921859545, Recall 0.746071133168\n",
    "* #12: Precision 0.908163265306, Recall 0.736145574855\n",
    "* #13: Precision 0.880445795339, Recall 0.718775847808\n",
    "* #14: Precision 0.890816326531, Recall 0.722084367246\n",
    "* #15: Precision 0.907237512742, Recall 0.736145574855\n",
    "* \n",
    "* Schnitt Precision: 0.89307770475\n",
    "* Schnitt Recall: 0.732065067549\n",
    "\n",
    "#### Test mit Klassifikationsmatrix nach dem Bugfix\n",
    "* #1: Precision 0.806193806194, Recall 0.66694214876"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* #0 Precision 0.673469387755, Recall 0.568965517241\n",
      "* #1 Precision 0.706896551724, Recall 0.706896551724\n",
      "* #2 Precision 0.708333333333, Recall 0.586206896552\n",
      "* #3 Precision 0.76, Recall 0.655172413793\n",
      "* #4 Precision 0.62962962963, Recall 0.586206896552\n",
      "Precision mean: 0.695665780488\n",
      "Recall mean: 0.620689655172\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from imports.matrix_helper import MatrixHelper\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "matrix_helper = MatrixHelper()\n",
    "\n",
    "# Read pickle\n",
    "feature_matrix = matrix_helper.load_from_parse('data/feature_matrix_sparse_classification.pickle')[0]\n",
    "\n",
    "feature_matrix = feature_matrix[:1000, :]\n",
    "\n",
    "# Create own matrices for vulenrable and not vulnerable components\n",
    "vulnerable, not_vulnerable = matrix_helper.split_vulnerable_notvulnerable(feature_matrix)\n",
    "\n",
    "# Variables for Iteration\n",
    "precision_sum = 0\n",
    "recall_sum = 0\n",
    "number_of_iterations = 5\n",
    "\n",
    "\n",
    "for i in range(number_of_iterations):\n",
    "    # Split into training sets (2/3) and test sets (1/3)\n",
    "    not_vulnerable_training, not_vulnerable_test = matrix_helper.split_training_test(not_vulnerable, 2.0/3)\n",
    "    vulnerable_training, vulnerable_test = matrix_helper.split_training_test(vulnerable, 2.0/3)\n",
    "\n",
    "    # Concatenate vulnerable/not-vulnerable and split into training and target matrices\n",
    "    training_data, training_target = matrix_helper.create_data_target(not_vulnerable_training, vulnerable_training)\n",
    "    test_data, test_target = matrix_helper.create_data_target(not_vulnerable_test, vulnerable_test)\n",
    "\n",
    "    # Create classifier\n",
    "    clf = svm.SVC(kernel='linear', C=0.2)\n",
    "\n",
    "    # Fit model\n",
    "    clf.fit(training_data, training_target)\n",
    "\n",
    "    # Predict remaining data\n",
    "    target_prediction = clf.predict(test_data)\n",
    "\n",
    "    # Compute Precision-Recall\n",
    "    precision, recall, thresholds = precision_recall_curve(test_target, target_prediction)\n",
    "\n",
    "    precision_sum += precision[1]\n",
    "    recall_sum += recall[1]\n",
    "\n",
    "    # Print Precision and Recall\n",
    "    print('* #{} Precision {}, Recall {}'.format(i, precision[1], recall[1]))\n",
    "\n",
    "print('Precision mean: {}'.format(precision_sum / number_of_iterations))\n",
    "print('Recall mean: {}'.format(recall_sum / number_of_iterations))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verwundbare Komponenten im Testset:       18.6%\n",
      "Verwundbare Komponenten in Vorhersage:       15.4%\n",
      "------------------------------\n",
      "Precision 0.806193806194, Recall 0.66694214876\n",
      "time:       23.5min\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from imports.matrix_helper import MatrixHelper\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "matrix_helper = MatrixHelper()\n",
    "\n",
    "# Read pickle\n",
    "feature_matrix = matrix_helper.load_from_parse('data/feature_matrix_sparse_classification.pickle')[0]\n",
    "\n",
    "# Create own matrices for vulenrable and not vulnerable components\n",
    "vulnerable, not_vulnerable = matrix_helper.split_vulnerable_notvulnerable(feature_matrix)\n",
    "\n",
    "# Split into training sets (2/3) and test sets (1/3)\n",
    "not_vulnerable_training, not_vulnerable_test = matrix_helper.split_training_test(not_vulnerable, 2.0/3)\n",
    "vulnerable_training, vulnerable_test = matrix_helper.split_training_test(vulnerable, 2.0/3)\n",
    "\n",
    "# Concatenate vulnerable/not-vulnerable and split into training and target matrices\n",
    "training_data, training_target = matrix_helper.create_data_target(not_vulnerable_training, vulnerable_training)\n",
    "test_data, test_target = matrix_helper.create_data_target(not_vulnerable_test, vulnerable_test)\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "# Create classifier\n",
    "clf = svm.SVC(kernel='linear', C=0.2)\n",
    "\n",
    "# Fit model\n",
    "clf.fit(training_data, training_target)\n",
    "\n",
    "# Predict data\n",
    "target_prediction = clf.predict(test_data)\n",
    "\n",
    "# Compute Precision-Recall\n",
    "precision, recall, thresholds = precision_recall_curve(test_target, target_prediction)\n",
    "\n",
    "end = time.time()\n",
    "elapsed = (end - start) / 60\n",
    "\n",
    "# Print\n",
    "print(\"Verwundbare Komponenten im Testset: {0:10.1f}%\".format(matrix_helper.get_vulnerable_percentage(test_target)))\n",
    "print(\"Verwundbare Komponenten in Vorhersage: {0:10.1f}%\".format(matrix_helper.get_vulnerable_percentage(target_prediction)))\n",
    "print('------------------------------')\n",
    "print('Precision {}, Recall {}'.format(precision[1], recall[1]))\n",
    "print('time: {0:10.1f}min'.format(elapsed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
