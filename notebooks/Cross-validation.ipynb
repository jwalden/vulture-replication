{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn import svm\n",
    "from sklearn import tree\n",
    "\n",
    "from imports.matrix_helper import MatrixHelper\n",
    "from imports.prediction_helper import PredictionHelper\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "matrix_helper = MatrixHelper()\n",
    "sampling_factor=(2.0/3)\n",
    "\n",
    "def stratified_sampling(matrix):\n",
    "    # Create own matrices for vulenrable and not vulnerable entries\n",
    "    vulnerable_matrix = matrix_helper.get_vulnerable_components(matrix)\n",
    "    not_vulnerable_matrix = matrix_helper.get_not_vulnerable_components(matrix)\n",
    "\n",
    "    # Split into training sets (2/3) and test sets (1/3)\n",
    "    vulnerable_training, vulnerable_test = matrix_helper.split_training_test(vulnerable_matrix, sampling_factor)\n",
    "    not_vulnerable_training, not_vulnerable_test = matrix_helper.split_training_test(not_vulnerable_matrix, sampling_factor)\n",
    "\n",
    "    # Concatenate vulnerable/not-vulnerable\n",
    "    training_matrix = np.concatenate((not_vulnerable_training, vulnerable_training), axis=0)\n",
    "    test_matrix = np.concatenate((not_vulnerable_test, vulnerable_test), axis=0)\n",
    "\n",
    "    # Split into training and target matrices\n",
    "    training_data, training_target = matrix_helper.create_data_target(training_matrix)\n",
    "    test_data, test_target = matrix_helper.create_data_target(test_matrix)\n",
    "    \n",
    "    return training_data, training_target, test_data, test_target\n",
    "    \n",
    "\n",
    "# Read pickle\n",
    "#matrices = matrix_helper.load_from_parse('data/matrices/matrix_cla_incl_current.pickle')\n",
    "matrices = matrix_helper.load_from_parse('data/matrices/matrix_reg_incl_current.pickle')\n",
    "feature_matrix = matrices[0]\n",
    "#feature_matrix = feature_matrix[:100, :]\n",
    "\n",
    "total_score_list = []\n",
    "penalties = [0.05, 0.1, 0.5, 1.0, 5.0, 10.0]\n",
    "for penalty in penalties:\n",
    "    #clf = svm.LinearSVC(C=penalty)\n",
    "    clf = svm.SVR(C=penalty)\n",
    "    score_list = []\n",
    "    for i in range(5):\n",
    "        training_data, training_target, test_data, test_target = stratified_sampling(feature_matrix)\n",
    "        score = clf.fit(training_data, training_target).score(test_data, test_target)\n",
    "        score_list.append(score)\n",
    "    print('Penalty: {}, Average: {}'.format(penalty, sum(score_list) / float(len(score_list))))\n",
    "    total_score_list.append(sum(score_list) / float(len(score_list)))\n",
    "\n",
    "    \n",
    "figure = plt.figure()\n",
    "\n",
    "plt.xlabel('Penalty Parameter')\n",
    "plt.ylabel('Score')\n",
    "figure.suptitle('Cross Validation Scores')\n",
    "plt.semilogx(penalties, total_score_list)\n",
    "\n",
    "figure.savefig('outputs/penalty_parameter.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "go\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "from sklearn import svm\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from imports.matrix_helper import MatrixHelper\n",
    "\n",
    "matrix_helper = MatrixHelper()\n",
    "\n",
    "matrices = matrix_helper.load_from_parse('data/matrices/matrix_reg_incl_current.pickle')\n",
    "feature_matrix = matrices[0]\n",
    "#feature_matrix = feature_matrix[:100, :]\n",
    "features_count = feature_matrix.shape[1] - 1\n",
    "print('go')\n",
    "\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10], 'kernel': ['linear']}\n",
    "grid_search = GridSearchCV(svm.SVR(), param_grid, cv=5)\n",
    "grid_search.fit(feature_matrix[:, range(features_count)], feature_matrix[:, features_count])\n",
    "print(grid_search.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
